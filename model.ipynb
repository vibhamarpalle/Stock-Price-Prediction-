{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7vAGfSV9lnqL"
      },
      "outputs": [],
      "source": [
        "#train = pd.read_csv(\"/kaggle/input/ue21cs342aa2/train.csv\", index_col = 0)\n",
        "#test = pd.read_csv(\"/kaggle/input/ue21cs342aa2/test.csv\", index_col = 0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Installing the required libraries\n",
        "!pip install pmdarima\n",
        "\n",
        "# Importing the required libraries\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from statsmodels.tsa.seasonal import seasonal_decompose\n",
        "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "from pmdarima import auto_arima\n",
        "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "JMb5o3jhlrAT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The Date column is of type string. We're converting the Date column to the timestamp datatype.\n",
        "train[\"Date\"] = pd.to_datetime(train[\"Date\"])\n",
        "test[\"Date\"] = pd.to_datetime(test[\"Date\"])\n",
        "train\n",
        "type(train['Date'][0])"
      ],
      "metadata": {
        "id": "GspVVL5ilu1a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting the date column as index\n",
        "train.set_index(\"Date\", inplace=True)\n",
        "test.set_index(\"Date\", inplace=True)"
      ],
      "metadata": {
        "id": "k05Xr7ttl3Vt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting close price's signature\n",
        "plt.figure(figsize=(16, 10))\n",
        "plt.plot(train.index, train['Close'])\n",
        "plt.title('Stock Close Price Over Time')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Close Price')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OeP127xJl5ow"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Decomposition\n",
        "result = seasonal_decompose(train['Close'], model='additive', period=7)\n",
        "\n",
        "plt.figure(figsize=(20, 10))\n",
        "plt.subplot(4, 1, 1)\n",
        "plt.plot(train.index, train['Close'], label='Original Data')\n",
        "plt.title('Original Data')\n",
        "\n",
        "plt.subplot(4, 1, 2)\n",
        "plt.plot(train.index, result.trend, label='Trend')\n",
        "plt.title('Trend Component')\n",
        "\n",
        "plt.subplot(4, 1, 3)\n",
        "plt.plot(train.index, result.seasonal, label='Seasonal')\n",
        "plt.title('Seasonal Component')\n",
        "\n",
        "plt.subplot(4, 1, 4)\n",
        "plt.plot(train.index, result.resid, label='Residual')\n",
        "plt.title('Residual Component')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "nbzhZc3dl9ZB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting ACF and PACF plots to obtain p and q values\n",
        "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 8))\n",
        "plot_acf(train['Close'], lags=100, ax=ax1, title='Autocorrelation Function (ACF)')\n",
        "plot_pacf(train['Close'], lags=100, ax=ax2, title='Partial Autocorrelation Function (PACF)')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Q_5wyjIOmAKW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Computing the ADF statistic and p-values of the columns\n",
        "# Checking whether the columns are stationary or non-stationary.\n",
        "# We're also determining whether differencing is required.\n",
        "print(\"Column:Close\")\n",
        "result_close = adfuller(train['Close'])\n",
        "print('ADF Statistic:', result_close[0])\n",
        "print('p-value:', result_close[1])\n",
        "\n",
        "if result_close[1] > 0.05:\n",
        "    print(\"The data is non-stationary. Differencing is required.\")\n",
        "else:\n",
        "    print(\"The data is stationary.\")\n",
        "print()\n",
        "print(\"Column:Open\")\n",
        "result_open = adfuller(train['Open'])\n",
        "print('ADF Statistic:', result_open[0])\n",
        "print('p-value:', result_open[1])\n",
        "\n",
        "if result_open[1] > 0.05:\n",
        "    print(\"The data is non-stationary. Differencing is required.\")\n",
        "else:\n",
        "    print(\"The data is stationary.\")\n",
        "print()\n",
        "print(\"Column:Volume\")\n",
        "result_open = adfuller(train['Volume'])\n",
        "print('ADF Statistic:', result_open[0])\n",
        "print('p-value:', result_open[1])\n",
        "\n",
        "if result_open[1] > 0.05:\n",
        "    print(\"The data is non-stationary. Differencing is required.\")\n",
        "else:\n",
        "    print(\"The data is stationary.\")"
      ],
      "metadata": {
        "id": "zm-U2sTGmEHy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Applying log transformation to the Close column.\n",
        "train[\"Close_diff\"] = np.log(train[\"Close\"])\n",
        "span = 7\n",
        "train[\"Open_Lag1\"] = train[\"Open\"].shift(1)\n",
        "train[\"Open_Lag2\"] = train[\"Open\"].shift(2)\n",
        "train[\"Volume_Lag1\"] = train[\"Volume\"].shift(1)\n",
        "train[\"Open_EMA\"] = train[\"Open\"].ewm(span=span, adjust=False).mean()\n",
        "train['Volume_Ratio'] = train['Volume'] / train['Open']\n",
        "# train['Price_Rate_of_Change'] = train['Open'].pct_change()\n",
        "# train['Price_Momentum'] = train['Open'] - train['Open'].shift(1)\n",
        "train = train.dropna()\n",
        "\n",
        "\n",
        "test[\"Open_Lag1\"] = test[\"Open\"].shift(1)\n",
        "test[\"Open_Lag2\"] = test[\"Open\"].shift(2)\n",
        "test[\"Volume_Lag1\"] = test[\"Volume\"].shift(1)\n",
        "test[\"Open_EMA\"] = test[\"Open\"].ewm(span=span, adjust=False).mean()\n",
        "test['Volume_Ratio'] = test['Volume'] / test['Open']\n",
        "# test['Price_Rate_of_Change'] = test['Open'].pct_change()\n",
        "# test['Price_Momentum'] = test['Open'] - test['Open'].shift(1)\n",
        "test = test.bfill()\n",
        "train"
      ],
      "metadata": {
        "id": "Eg2jiYkxmIwr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the impact of the transformation on the Close data's ACF and PACF plots\n",
        "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 8))\n",
        "plot_acf(train['Close_diff'], lags=50, ax=ax1, title='Autocorrelation Function (ACF)')\n",
        "plot_pacf(train['Close_diff'], lags=100, ax=ax2, title='Partial Autocorrelation Function (PACF)')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TTM3W8c-mMg9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def hyperparameter_tuning(train_data, exogenous_data):\n",
        "    stepwise_fit = auto_arima(\n",
        "        train_data['Close_diff'],\n",
        "        exogenous=exogenous_data,\n",
        "        seasonal=True,\n",
        "        stepwise=True,\n",
        "        suppress_warnings=True,\n",
        "        error_action=\"ignore\",\n",
        "        seasonal_order=(1,0,1,12)\n",
        "    )\n",
        "    return stepwise_fit.order, stepwise_fit.seasonal_order"
      ],
      "metadata": {
        "id": "HnldkKAzmPN5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting the data into 80-20 train-test\n",
        "n_splits = 5\n",
        "mse_results = []\n",
        "tscv = TimeSeriesSplit(n_splits=n_splits)\n",
        "for train_index, test_index in tscv.split(train):\n",
        "    train_data = train.iloc[train_index]\n",
        "    test_data = train.iloc[test_index]\n",
        "    exogenous_data = train_data[['Open','Volume','Open_EMA','Volume_Ratio']]\n",
        "    order, seasonal_order = hyperparameter_tuning(train_data, exogenous_data)\n",
        "    #p, d, q, P, D, Q, S = (2, 1, 1, 1, 1, 2, 7)\n",
        "    model = SARIMAX(train_data['Close_diff'], order=(2,1,1), seasonal_order=(1,1,2,7), exog=exogenous_data)\n",
        "    result = model.fit(disp=False)\n",
        "\n",
        "forecast_steps = len(test_data)\n",
        "exogenous_test_data = test_data[['Open', 'Volume','Open_EMA','Volume_Ratio']]\n",
        "forecast = result.get_forecast(steps=forecast_steps, exog=exogenous_test_data)\n",
        "\n",
        "forecasted_values = forecast.predicted_mean\n",
        "confidence_intervals = forecast.conf_int()\n",
        "\n",
        "actual_close = test_data['Close_diff']\n",
        "smape = 100 * 2 * np.mean(np.abs(forecasted_values - actual_close) / (np.abs(forecasted_values) + np.abs(actual_close)))\n",
        "print(\"SMAPE:\", smape)\n",
        "\n",
        "mse = mean_squared_error(actual_close, forecasted_values)\n",
        "print(\"Mean Squared Error:\", mse)"
      ],
      "metadata": {
        "id": "VqYHju-HmSfu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(test_data.index, test_data['Close_diff'], label='Actual Close', color='blue')\n",
        "plt.plot(test_data.index, forecasted_values, label='Forecasted Close', color='red')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Close Price')\n",
        "plt.legend()\n",
        "plt.title('Forecasts vs. Actual Data')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "gdFCbghMmVEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_order, best_seasonal_order = None, None\n",
        "exogenous_data = train[['Open','Volume','Open_EMA','Volume_Ratio']]\n",
        "stepwise_fit = auto_arima(\n",
        "    train['Close_diff'],\n",
        "    exogenous=exogenous_data,\n",
        "    seasonal=True,\n",
        "    stepwise=True,\n",
        "    suppress_warnings=True,\n",
        "    error_action=\"ignore\",\n",
        "    m=7,  # Seasonal period = 7 (one week)\n",
        "    max_order=(5, 2, 5, 7) # The maximum values P, D, Q, S can take\n",
        ")\n",
        "\n",
        "# Get the best order and seasonal order\n",
        "best_order, best_seasonal_order = stepwise_fit.order, stepwise_fit.seasonal_order\n",
        "\n",
        "# Use these best hyperparameters to create your SARIMA model\n",
        "model = SARIMAX(train['Close_diff'], order=best_order, seasonal_order=best_seasonal_order, exog=exogenous_data)\n",
        "result_new = model.fit(disp=False)\n",
        "\n",
        "# Forecast future values using the test.csv data\n",
        "exog_future = test[['Open', 'Volume','Open_EMA','Volume_Ratio']]\n",
        "forecast_future = result_new.get_forecast(steps=100, exog=exog_future)\n",
        "\n",
        "forecasted_values_final = forecast_future.predicted_mean\n",
        "confidence_intervals = forecast_future.conf_int()\n",
        "\n",
        "forecasted_values_og = np.exp(forecasted_values_final)\n",
        "forecasted_values_og"
      ],
      "metadata": {
        "id": "8ej5ZalWmXtP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test['Close']=forecasted_values_og\n",
        "test"
      ],
      "metadata": {
        "id": "1mMj8v3nmZ4w"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}